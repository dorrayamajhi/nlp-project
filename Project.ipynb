{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from scipy.misc import imread\n",
    "from scipy import sparse\n",
    "import scipy.stats as ss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import string\n",
    "import re    #for regex\n",
    "#import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "# Tweet tokenizer does not split at apostophes which is what we want\n",
    "from nltk.tokenize import TweetTokenizer \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start_time=time.time()\n",
    "color = sns.color_palette()\n",
    "sns.set_style(\"dark\")\n",
    "#eng_stopwords = set(stopwords.words(\"english\"))\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "tokenizer=TweetTokenizer()\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('C:/Users/Admin/Downloads/all/train.csv')\n",
    "test_df = pd.read_csv('C:/Users/Admin/Downloads/all/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_target = ['obscene','insult','toxic','severe_toxic','identity_hate','threat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_target2=train_df[['obscene','insult','toxic','severe_toxic','identity_hate','threat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obscene           8449\n",
       "insult            7877\n",
       "toxic            15294\n",
       "severe_toxic      1595\n",
       "identity_hate     1405\n",
       "threat             478\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_target2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obscene          0.052948\n",
       "insult           0.049364\n",
       "toxic            0.095844\n",
       "severe_toxic     0.009996\n",
       "identity_hate    0.008805\n",
       "threat           0.002996\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_target2.sum()/len(cols_target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in numeric columns\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for any 'null' comment\n",
    "no_comment = train_df[train_df['comment_text'].isnull()]\n",
    "len(no_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the character length for the rows in the training data and record these\n",
    "train_df['char_length'] = train_df['comment_text'].apply(lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at the histogram plot for text length\n",
    "sns.set()\n",
    "train_df['char_length'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the comment text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the comment_text in train_df [Thanks to Pulkit Jha for the useful pointer.]\n",
    "train_df['comment_text'] = train_df['comment_text'].map(lambda com : clean_text(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the comment_text in test_df \n",
    "test_df['comment_text'] = test_df['comment_text'].map(lambda com : clean_text(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop('char_length',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.comment_text\n",
    "test_X = test_df.comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and instantiate TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(max_features=5000,stop_words='english')\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3178792 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the vocabulary in the training data, then use it to create a document-term matrix\n",
    "X_dtm = vect.fit_transform(X)\n",
    "# examine the document-term matrix created from X_train\n",
    "X_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<153164x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2618972 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the test data using the earlier fitted vocabulary, into a document-term matrix\n",
    "test_X_dtm = vect.transform(test_X)\n",
    "# examine the document-term matrix from X_test\n",
    "test_X_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### building a multi-label classifier using Logistic Regression\n",
    "# import and instantiate the Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing obscene\n",
      "Training accuracy is 0.9832300355327722\n",
      "... Processing insult\n",
      "Training accuracy is 0.9755469352200588\n",
      "... Processing toxic\n",
      "Training accuracy is 0.9639846839337975\n",
      "... Processing severe_toxic\n",
      "Training accuracy is 0.9920724943755445\n",
      "... Processing identity_hate\n",
      "Training accuracy is 0.9939713356436947\n",
      "... Processing threat\n",
      "Training accuracy is 0.9981199591404453\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=12.0)\n",
    "for label in cols_target:\n",
    "    print('... Processing {}'.format(label))\n",
    "    y = train_df[label]    \n",
    "    logreg.fit(X_dtm, y)\n",
    "   \n",
    "    y_pred_X = logreg.predict(X_dtm)\n",
    "    print('Training accuracy is {}'.format(accuracy_score(y, y_pred_X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing obscene\n",
      "Training accuracy is 0.9842264571883362\n",
      "... Processing insult\n",
      "Training accuracy is 0.976518289664162\n",
      "... Processing toxic\n",
      "Training accuracy is 0.9645048285716076\n",
      "... Processing severe_toxic\n",
      "Training accuracy is 0.9927681094935796\n",
      "... Processing identity_hate\n",
      "Training accuracy is 0.9948925556648764\n",
      "... Processing threat\n",
      "Training accuracy is 0.998828107864211\n"
     ]
    }
   ],
   "source": [
    "#WITH l1\n",
    "logreg =LogisticRegression(C=12,penalty='l1',tol=0.01)\n",
    "for label in cols_target:\n",
    "    print('... Processing {}'.format(label))\n",
    "    y = train_df[label]    \n",
    "    logreg.fit(X_dtm, y)   \n",
    "    y_pred_X = logreg.predict(X_dtm)\n",
    "    print('Training accuracy is {}'.format(accuracy_score(y, y_pred_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing obscene\n",
      "Training accuracy is 0.9828540273608614\n",
      "... Processing insult\n",
      "Training accuracy is 0.9750330573851138\n",
      "... Processing toxic\n",
      "Training accuracy is 0.9624681176404234\n",
      "... Processing severe_toxic\n",
      "Training accuracy is 0.9920098263468926\n",
      "... Processing identity_hate\n",
      "Training accuracy is 0.9938836004035821\n",
      "... Processing threat\n",
      "Training accuracy is 0.9981136923375802\n"
     ]
    }
   ],
   "source": [
    "#with l2\n",
    "logreg =LogisticRegression(C=12,penalty='l2',tol=0.01)\n",
    "for label in cols_target:\n",
    "    print('... Processing {}'.format(label))\n",
    "    y = train_df[label]    \n",
    "    logreg.fit(X_dtm, y)   \n",
    "    y_pred_X = logreg.predict(X_dtm)\n",
    "    print('Training accuracy is {}'.format(accuracy_score(y, y_pred_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
